DataConfig:
    valid_label: [1,2,3,4,5,6,7,8,9]
    anomaly_label: [0]
    contamination: 0.01 # Amount of anomalies in dataset in %
    test_size: 0.2 # Ratio between train and test dataset size
    random_state: 42 # State of the random number generator

DeepSwarm: # DeepSwarm object responsible for providing a user-facing interface
    save_folder:
    metrics: accuracy # Metrics to evaluate the models
    max_depth: 10 # Maximum and a minimum depth of hidden layers
    min_depth: 1 # on one side of the Autoencoder
    reuse_patience: 1 # Number of times weight can be reused

    aco: # Ant colony optimization object
        pheromone:
            start: 0.1 # Starting pheromone value
            decay: 0.1 # Local pheromone decay
            evaporation: 0.1 # Global pheromone decay
            verbose: 1 # Logging components
        greediness: 0.50 # Greediness of ants
        ant_count: 10 # Maximum amount of ants (models)
        latent_dim: 16 # Dimension of compressed space in Autoencoder

    anomaly:
        quantile: 0.98 # Instance out of this quantile are anomalies

    backend:
        epochs: 75 # Number of epochs per ant (model)
        batch_size: 32 # Number of batches in epoch per ant (model)
        patience: 5 # Early stopping during the training
        verbose: 1 # Logging components
        optimizer: adam # Optimizer for training
        loss: binary_crossentropy # Loss function for training

Nodes: # Layers types used when building the topology

    InputNode: # First layer in encoder model
        type: Input # Type of layer in Keras
        attributes:
            shape: [!!python/tuple [28, 28, 1]]# Shape of input
        transitions:
            DenseNode: 1.0 # Transition possibility for next layer

    InputDecoderNode: # First layer in decoder model
        type: Input
        attributes:
            shape: [ !!python/tuple [ 14 ] ]
        transitions:
            DenseNode: 1.0

    FlattenNode: # Flatten layer before latent space in Autoencoder
        type: Flatten
        attributes: { }
        transitions:
            DenseNode: 1.0

    ReShapeNode: # Layer used when decoding back from latent space
        type: Reshape
        attributes:
            target_shape: [ !!python/tuple [ 7, 7, 1 ] ]
        transitions:
            DenseNode: 1.0

    DenseNode: # Hidden layer in autoencoder
        type: Dense
        attributes:
            output_size: [128, 64, 32, 16, 8, 4, 2]
            activation: [ReLU, LeakyReLU,Tanh]
        transitions:
            DenseNode: 1.0

    OutputNode: # Final output layer in decoder model
        type: Output
        attributes:
            output_size: [1]
            activation: [Sigmoid]
        transitions: {}
